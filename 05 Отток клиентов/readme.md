# Отток клиентов
### Цели проекта
Построить модель с предельно большим значением F1-меры.  
  
### Задачи проекта
1. провести предобработку данных;
2. разбить данные на выборки;  
3. исследовать модели,
    - DecisionTreeClassifier,
    - RandomForestClassifier,
    - LogisticRegression;
4. проверить метрики;
5. убрать дисбаланс классов;
6. протестировать финальную модель;
7. сделать общие выводы.

### Данные
Данные об уходе клиентов из "Бета-Банка".

### Описание данных
Признаки
- <code>RowNumber</code> — индекс строки в данных
- <code>CustomerId</code> — уникальный идентификатор клиента
- <code>Surname</code> — фамилия
- <code>CreditScore</code> — кредитный рейтинг
- <code>Geography</code> — страна проживания
- <code>Gender</code> — пол
- <code>Age</code> — возраст
- <code>Tenure</code> — сколько лет человек является клиентом банка
- <code>Balance</code> — баланс на счёте
- <code>NumOfProducts</code> — количество продуктов банка, используемых клиентом
- <code>HasCrCard</code> — наличие кредитной карты
- <code>IsActiveMember</code> — активность клиента
- <code>EstimatedSalary</code> — предполагаемая зарплата  
  
Целевой признак
- <code>Exited</code> — факт ухода клиента

### Выводы
1. <b>Изучен файл</b>  
    - Пропуски в данных были заменены на 0.  
    - Тип данных в <code>Tenure</code> изменён на <i>int</i>.  
    - Удалены строки, в которых <code>EstimatedSalary</code> меньше 200. 
2. <b>Данные разбиты на выборки</b> 
    - Вызовом <i>pd.get_dummies()</i> c аргументом <i>drop_first</i> преобразовался не только столбец <code>Gender</code>, но и столбец <code>Geography</code>, так как в нём всего 3 уникальных значения.
    - Данные были разбиты на три выборки: обучающая, тренировочная и валидационная в отношении 3:1:1 соответственно.  
    - Проведено масштабирование признаков - признаки приведены к одному масштабу.
3. <b>Исследованы модели</b> 
    - DecisionTreeClassifier: accuracy лучшей модели = 0.79.
    - RandomForestClassifier: accuracy лучшей модели = 0.87.  
    - LogisticRegression: accuracy лучшей модели = 0.81.
4. <b>Проведена работа с дисбалансом классов</b> 
    - Написанной функцией была увеличена выборка.
    - Проведено обучение модели на сбалансированной выборке: 
        1. DecisionTreeClassifier: F1-мера = 0.49815043156596794.
        2. RandomForestClassifier: F1-мера = 0.592057761732852.  
        3. LogisticRegression: F1-мера = 0.4802110817941952.
5. <b>Проверена модель на тестовой выборке</b>
